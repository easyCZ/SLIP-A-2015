Filip Frahm
===========

With recent news about NSA surveillance, large scale data collection seems to have a negative connotation in our society. While fear for ones' privacy is justified,large scale data collection can be of tremendous benefit. An application of it that stands out is the imrpovement of our society's health. At the University of Edinburgh, researcher Andy Sims is using bioinformatics and genetic data to predict which cancer drugs are most appropriate for a breat cancer patient[^L3]. In San Francisco, Google-backed company Calico[^L2] gained access to Ancestry.com's genetic database with the intention of using genetic and family tree related data to improve the human lifespan.[^L1]   

The goal for our project was to create a vest that would 1)have as many health related sensors as possible and 2)process and present that data to the user. We believe that such a vest would not only be attractive for personal use but that it could, similarly to the examples above, also advance medical research by providing data. In the duration of the course, a temperature sensor and an electrocardiogram(ECG) were installed to a vest. Further, a website and mobile application were created to process and present the data. While a respiratory sensor has not yet been integrated to the vest some research regarding future applications of such a sensor has been completed.  

My role in the project was to process data. Data processing included the conversion of data from the ECG to a beats per minute(BPM) value. Additionally, it was my task to explore potential uses of a respiratory sensor (RESpeck).  

ECG Data Processing
===========

Specifications
-----------

The requirements for the ECG data processing code (BPM code) were to take ECG data from the server and to then return a BPM. Data passed from the server would be in a python dictionary with unix timestamps as keys and integers representing voltage (voltstamps) as values. Voltstamps theoretically range from zero to 1024 but only range from zero to around 360 in practice. In available data, data points were typically between 0.001 and 0.05 seconds apart. In order to be able to provide a live BPM feed, the BPM code was to be applied to a moving window with length between zero and ten seconds. Of course this moving window always consists of consecutive data points.

Figure 1

Method
----------

The BPM code can be divided into two major parts. The first and more computationally expensive one parses through a given window of data and attempts to identify the timestamps and voltstamps of heart beats. In the process, more information about the data is collected. The second part of the code uses the previously collected information to predict how many beats would occur over 60 seconds.

### Beat Detection and Step Structure

ject the approach to finding a beat detecting method was somewhat manual. A method that would theoretically detect beats would be chosen and then tested against available data. This led to some issues. Firstly, little data was available for testin and the manual approach allowed little flexibility. As a result, methods would frequently work for small samples, but not be flexible enough to work for larger samples. Secondly, the varying density of datapoints, requires more versatile methods. A combination of different methods was required to attain a good output.  

To avoid the above-listed issues, a computational approach was pursued. Instead of choosing methods manually, a fixed structure (the step structure) was created. The step structure itself remains the same, but it allows for the choosing of different combinations of methods and benchmarks within it. To determine the optimal combination of methods and benchmarks a testing environment was created (detailed in TestingITALICS). The computational approach doesn't just try more options and parse more data than the manual approach, it also easily adapts to new data.  

The step structure code starts with the window of data as described before and ends with a dictionary of suspected beats. It does so in four steps outlined in Figure 2ITALICS. The individual methods(or conditions) for each step are described in Figure 3ITALICS.   

Figure 2

Figure 3

Note that for all the step one conditions any of the following five logical statements can be applied to the condition:
1) Whether the condition is met or not has no impact on the selection of the iter_windowITALICS.
2) If the condition is met, the iter_windowITALICS will be selected regardless of the results of other methods.
3) If the condition is not met, the iter_windowITALICS will be selected regardless of the results of other methods.
4) Unless 2) or 3) occurs, this condition must not be met for the iter_windowITALICS to be selected.
5) Unless 2) or 3) occurs, this condition must be met for the iter_windowITALICS to be selected.

As a result of testing (detailed in TestingITALICS), the best choice of benchmarks and methods emerged to be HELP.

### Beats per Minute

The idea of the BPM is not to project how many beats a user will have in one minute, but rather to let the user know how many beats in a minute he would have at the current rate. This makes the generation of a BPM value simple (since the beats have already been identified). We simply divide 60 seconds by the average time between beats.

Simplifying,

Figure 4

#### Error Detection and Adjustment

Since the ECG is easily affected by movement, the BPM code needs to adjust to unusable data. It does so in two ways. Firstly, it flags data windows with extremely high variance (variance > 60). Secondly, it discards iter_windowsITALICS that contain zero voltstamps. In practice zero voltstamps only occur as a symptom of extreme noise (the normal range is 140 to 250). The percentage of iter_windowsITALICS are used is then computed and used to adjust the BPM formula as described in Figure 5ITALICS below.

Figure 5

This adjustment is not correct. This method was chosen due to time constraints, but an alternative method is suggested implicitly in the criticism below. Given a data window such as the one in Figure 6ITALICS below, the effect of the error adjustment depends on where the error occurs. The issue with the current method lies in the fact that data outside of t1 and tn HELP is not considered for the BPM but it is considered in the error adjustment. Figure 7ITALICS discusses different scenarios.

Figure 6

Figure 7
TABLE Index | Scenario | Current Adjustment | Correct Adjustment | Error | Summary
1|
Scenario: Error occurs only in between t1 and tn HELP.
Current Adjustment: 100*BPM¬old / percentage of windows used HELP
Correct Adjustment: BPM¬old*(tn-t1)/(tn-t1-error_duration) HELP
Error Bounds: HELP
Summary: Adujstment is not severe enough.
2|
Scenario: Error occurs only outside of t1 and tn HELP
Current Adjustment: 100*BPM¬old / percentage of windows used HELP
Correct Adjustment: No adjustment
Error Bounds: HELP
Summary: Adjustment is too severe.
3|
Scenario: Error occurs inbetween t1 and tn HELP and outside of t1 and tn HELP
Current Adjustment: 100*BPM¬old / percentage of windows used HELP
Correct Adjustment: BPM¬old*(tn-t1)/(tn-t1-inside_error_duration) HELP
Error Bounds: weighted combination of 1 and 2 HELP so worst one.
Summary: Adjustment could be too severe or not sever enough.

In testing, data windows with high error rates (error > X% HELP) were discarded. Nonetheless, the above adjustment could cause significant error. Calculations for the above error bounds are provided in  the CalculationsITALICS seciont (Calculations 1ITALICS).

### Testing

The goals for testing were to determine the best possible benchmarks and combinations of methods (setting) for the step structure and to measure their effectiveness. Further objectives were to graph the effect of changing the minimum spacing between beats, the length of iter_windowsITALICS and most importantly the length of data windows.

Figure 8

#### Testing Environment

Goals two through five quickly follow from goal one, so this section will focus on reaching goal one. A more mathematical way of formulating the problem would be to see all possible settings as a set (X HELP). Testing them is equivalent to mapping this set to another set(Q HELP), where each element is a measure of quality,to then choose the best quality and map it back to X HELP. The idea behind the testing environment was to emulate this process. Of course X is far too large to test every setting. The limitations of the testing environment and their impact is discussed in Testing ProcedureITALICS.

Figure 9

Since the BPM code is contained in a file (services.py) which is then compiled and used in the server, the testing environment had to be created in a seperate file (local.py). Other specifications required for effective testing are described in Figure 10ITALICS. Figure 11ITALICS displays how information moves between local.py services.py and a CSV file. Figure 12ITALICS lists the information that was passed from services.py to local.py.

Figure 10

Figure 11

Note that for testing purposes the order in which the code processes data windows is irrelevant as the BPM code draws no connection between consecutive data windows.

Figure 12

#### Measuring Quality

Referring back to the mathematical formulation of the problem, we need a function (f(x):X->Q HELP) that measures the quality of a particular setting. As already suggested in the pseudo code of Figure 11ITALICS, a Monte Carlo style approach was used to determine this funciton. First, a measure of quality for a particular setting and data window was defined (f_hat(x) HELP). This measure of quality was then applied to as many data windows as possible (with the same setting) to generate an expected value for the quality of the setting (f(x) HELP). Three measures were considered for f_hat(x) HELP.

Figure 13

Measure one is far too inaccurate to be of use and measure three is too impractical. Measure two has significant issues, but is the only viable method. Figures 14ITALICS and 15 ITALICS show an attempt to quantify them. The calculations behind the error bounds are in Calculation 2ITALICS.

Figure 14

An issure not addressed in Figure 14ITALICS is that the spacing of beats does not always matter and different types deviation of the computed heart beats from the real heart beats have different impacts on the quality measure. In order to save computational cost not all available data windows were evaluated in the testing. This has further impacts on the quality measure. The results below were generated by considering a sparse iteration to be an iteration that uses each data point exactly once (for example by dividing all available data into evenly spaced data windows). Dense iteration was considered to be an iteration that fixes window length and only changes the window by one data points each iteration. Results for changes in the dense iteration are always presented as an average of the effect on all data windows relevant to the described deviation. To generate the results in Figure 15ITALICS it was assumed that all heart beats are read correctly except the ones described in each scenario.

Figure 15

#### Testing Procedure

In my experience, it took about 0.017 seconds for a data window containg 200 data points to be evaluated. 200 data points was chosen as window length because it 
typically correspond to X seconds HELP, 
which is large enough to generate a BPM, but not so large that the spacing of beats can be uneven without strongly influencing the BPM. Having set restricted run time
to 24 hours (personal choice) this allowing for roughly 5,000,000 data windows of size 200 to be evaluated. The data available, attached in Appendix 1ITALICS, consists
of 5.5 minutes of data from three different subjects. The data contains intentional movement to make testing more realistic. Other data not considered in the 
experiment was collected using electrodes. This was deemed irrelevant as there was significantly less noise. The 5.5 minutes of data corresponds to X data points HELP
and therefore provide roughly X-600 data windows to be evaluated. Additionally, there were X HELP methods combinations to choose from along with X HELP benchmarks and 
constants. This left a total of XXX HELP data windows to be evaluated. Obviously this number is far larger than our limitation of 5,000,000. 

By selecting the sparse iteration method the number of data windows to be evaluated was cut down to XXX HELP. Further, the number of considered methods was reduced. 
Instead of the methods from Figure 3ITALICS, only the methods from figure 16ITALICS were considered. For more reductions in computational cost, the flow chart in 
Figure 17ITALICS was followed. This flow chart is clearly imperfect. Testing for the best methods and then using those results to test for constants and benchmarks
leaves a gap. This approach limnits results to methods that work well with the chosen benchmarks and constants, preventing potentially effective combinations from 
being selected. I decided to test for methods first because I had a better feeling for which ranges would be acceptable for constants and benchmarks (from informal 
testing), but I had very little idea about which methods would work most effectively.

Regarding the min_spacingITALICS, window_sizeITALICS and iter_windowITALICS constants, I worked under the theoretical assumption that neither of them should have an
impact on the data while they are within some accpetable range. 

Figure 17

This left XXX help data windows to be evaluated for phase 1 testing.

#### Testing Results

The results of phases one, two and three can be found in Appendix 2ITALICS, Appendix 3ITALICS and Appendix 4ITALICS respectively. The best setting was found to be X HELP. Elimination occured as described in Figures 18ITALICS, 19ITALICS, 20ITALICS and 21ITALICS.

Figure 18

Figure 19

Figure 20

Figure 21

In order to better test the resulting setting, it was applied the available data using dense iteration. The result was X HELP.

### Method Evaluation and Improvements

The phase 3 graphs from the previous section were slightly worrying as you would expect the accuracy of the BPM code to increase with window size. Instead, the accuracy decreased. While this may be partially attributed to increased exposure to error data(the sparse method was used) it suggests that the measuring criteria and testing procedure were flawed (the best solution is not generalisable). This notion is supported by the final test using dense iteration as BPM deviated twice as much. Figure 22ITALICS provides suggestions for improvement.

Figure 22

Respiratory Sensore Research
=========

The purpose of this section is to explore potential future uses of a respiratory sensor as part of the UberVest. The two explored potential uses of respiratory monitoring (more specifically monitoring of breathing rate and mean inspiratory flow during recovery after exercise) were the ranking of users' fitness level and the diagnosis of respiratory disease. To determine whether breathing rate can be an effective measure of fitness, 10 participants with know fitness levels completed a set of exercises. Linear regression was applied to determine the least squares estimation of a formula for respiratory fitness (given breathing data in recovery from exercise).

In another experiment, mean inspiratory flow and heart rate during recovery after exercise were monitored in young healthy individuals to determine whether there was a correlation between the two. In some cases the comparison of expiratory flow to predicted expiratory flow is used to diagnose COPD [7]. This experiment was designed to develop some familiarity in making a similar diagnosis.

Mean Inspiratory Flow vs. Heart Rate Experiment
---------

### Method

1. Measured breathing and heart rate at rest for one minute. People are more inclined to breathe abdominally when lying on their back and the respiratory sensor 
(RESpeck) measures breathing near the stomach, participants were asked to lie down on their back for all measurements of breathing and heart rate.
2. Participants ran on the treadmill for five minutes at ten km/h.
3. Measurements were taken as described in step 1. Measurements were taken until the heart rate calmed down to 99 BPM. Further cool down was deemed to time consuming.
4. Participants ran on the treadmill while I increased the speed until participants asked me stop the treadmill. Participants ran at the following speeds; one minute
at 10 km/h and 11 km/h followed by 30 seconds at each of the following speeds 12 km/h, 14km/h, 16km/h, 17 km/h, 18 km/h, 19 km/h, 20 km/h, 21 km/h, 22 km/h, 23 km/h 
and 24 km/h. The earliest participant to quit, quit after reaching 16km/h, the last quit after reaching 24 km/h.
5. Measurements were taken as described in step 3.

### Participants

Only five participants participated in the experiment. All of them are aged between 21 and 23 and are of good health. Four participants were male, one participant was female. No smokers participated and all five participants enjoyed recreational (at least weekly) exercise.

### Data Collection and Processing

The respiratory sensor used is called RESpeck. It measures breathing near the stomach using an accelerometer. A data sample is attached in Appendix 5ITALICS. Heart rate was measured using a POLAR FT4M device. The device failed for one out of five participants, requiring the heart rate monitor of the treadmill to be used. The heart rate as recorded by either device was filmed and synced to data collected using the RESpeck.

Little data processing was required for this experiment. Mean inspiratory flow is given by MIF = IV/ID HELP. The formula is derived from Figure 23ITALICS. 

Figure 23

### Results and Evaluation (level 3 heading)

While heart rate decreased in a nice curve with increasing slope (see Figure 24ITALICS), there was no recognisable pattern to the mean inspiratory flow during recovery from exercise (see Figure 25 ITALICS). The exception to this observation is Figure 26ITALICS. From subjective observations during the experiment, breathing seemed more aggressive initially and then cooled down. While it is likely that there is no trend, it is possible that the lack of trend in the mean inspiratory flow during recovery is a result of error in data collection. This error could be a result of participant movement or of the breathing signal being normalised. Since I am not fully aware of how the breathing signal algorithm works, I can neither confirm nor deny that notion. However, it is possible to conclude that in the generated data mean inpiratory flow is not correlated to heart rate.

Fitness Ranking Experiment
-----------

More specifically than simply ranking users by fitness, the goal of this experiment was to devise a formula that would return a fitness score to the user after he has completed a specified set of exercises.

### Method, Participants and Data Collection

The exact details for the actual data collection are not available to as I did not carry out the experiment. However, I know the following; ten respiratory disease patients aged 45 and above completed 10 exercises and measured their breathing rate (using a RESpeck) after each of the exercises. Their breathing at rest was also measured. Further, comments about the fitness of paprticipants and a ranking of their fitness was included.

### Data Processing

Mathematically, this problem is a linear regression problem. We generate a matrix X HELP from our data, where the ith row HELP contains the ith HELP participants scores for different metrics (such as the average breathing rate, the maximum breathing rate or the variance of breathing rates) or exercises. From the given fitness ranking of our participants we generate a vector y, where the ith HELP row contains the overall fitness score of the ith HELP participant. We are now looking for a vector w HELP such that w minimises the least squares summation := summation (yi - Xwi). This vector w is then given by the formula HELP regression formula or it can simply be computed using y\X HELP in Matlab.

The challenging part is choosing XHELP. The number of rows is fixed at ten, but how can we choose our column dimension and how do we assign values to each column? The only two options that come to mind are to assign different scores to different exercises and to assign different scores to different metrics. Considering the four metrics; average breathing rate, breathing rate variance, minimum breathing rate and maximum breathing rate and the eleven different exercises (including at rest), this gives us 44 different scores to evaluate. However, the mathematical formulation of the problem gives us some restrictions. To attain a sensible answer, the row dimension of X HELP must be larger than or equal to it's column dimension (an underdetermined system would lead to multiple dimensioned solution spaced). In fact the larger its row dimension is in relation to its column dimension the better. Obviously 44 is larger than 10 so the number of scores needs to be cut down. Just considering one metric for each exercise would yield 11 and still not be sufficient. Grouping exercises would be possible but seems futile because we don't know the details of the experiment. Considering each metric for all the exercises and then averaging over all the exercises would reduce the number of scores to four, leaving us with our matrix X HELP.

Having chosen what should be score, there is still need for a way to score it. The method chosen here uses the sample mean and variance to generate a normal distribution, emulating a larger population. Each metric for each exercise for each participant can then be located on this normal distribution returning what percentile the participant scored for that particular metric and exercise.

Figure 27

The resulting w is HELP, where w provides weights for [avg,min,max,var] respecively. 

###	Results

We can apply w HELP that was sloved for in this experiment and the way of generating X to data from the previous experiment to test the quality of the method. The resulting ranking can then be compared to several other methods of ranking participants.

Figure 28 

### Conclusion

The rankings of the five participants vary too much to be a useful indicator of how successful the method is. For better testing, the experiment could be expanded.
























#### Circuit refinement

The initial circuit provided a recognizable ECG trace, shown below.

<table>
  <tr>
    <td>
      <img alt="Initial ECG circuit output before filtering" src="waveforms/ECG without filter.png">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      Initial ECG circuit output before filtering
    </td>
  </tr>
</table>

Although recognizable, the trace obtained contains a large amount of noise as
the first iteration of the circuit made little attempt to filter noise.

Using a Picoscope, Roy and I was able to identify the frequency of the noise introduced:

<table>
  <tr>
    <td>
      <img alt="Frequency analysis of the output of the initial ECG circuit"
           src="waveforms/ecg without filter frequency.png">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      Frequency analysis of the output of the initial ECG circuit
    </td>
  </tr>
</table>

We identified the troublesome frequencies as being 50Hz and its harmonics
(100Hz, 200Hz, 400Hz, etc), which was likely introduced by our power supply and
may not be a problem when the device is running on batteries.
However, as these are beyond our desired signal frequency of 10Hz we were able
to simply add a 2nd order low pass filter to remove the noise.

I was responsible for designing the second-order low pass filter, which took the
form of a standard operational amplifier configuration (pictured below).

<table>
  <tr>
    <td>
      <img alt="A standard second order low pass filter" src="pictures/Second_order_low_pass_filter.svg">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      A standard second order low pass filter
    </td>
  </tr>
</table>

The values chosen were as follows:

<table class="table">
  <tr>
    <td>R_1</td><td>7.5K</td>
  </tr>
  <tr>
    <td>R_2</td><td>15K</td>
  </tr>
  <tr>
    <td>C_1</td><td>1µF</td>
  </tr>
  <tr>
    <td>C_2</td><td>1µF</td>
  </tr>
</table>

The cut-off frequency of the circuit above is calculated as follows:

$$
  f_c = \frac{1}{2 \pi \sqrt{R_1 R_2 C_1 C_2}}
\\
  f_c = \frac{1}{2 \pi \sqrt{7.5K \times 15K \times 1µ \times 1µ}}
\\
  f_c = 15Hz
$$

The addition of the low pass filter had a significant impact, resulting in the
following output:

<table>
  <tr>
    <td>
      <img alt="ECG trace with filter" src="waveforms/ECG output waveform.png">
    </td>
    <td>
      <img alt="ECG frequency with filter" src="waveforms/Spectrum with 2nd order filter_1.png">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      ECG trace once the second order filter has been applied
    </td>
    <td>
      Frequency analysis of the filtered output
    </td>
  </tr>
</table>

The frequency trace clearly shows our new 40dB/decade roll-off above the
frequencies of interest, effectively removing the majority of noise present.

#### Final ECG Circuit Schematic

![ECG Schematic](pictures/ecg circuit.jpg)

#### Circuit Evaluation

The ECG circuit generally performed pretty well, with P, Q, R, S and T sections
of the trace clearly visible.

The filter added to the initial design reduced the amplitude of noise at 50Hz by
20dB (as shown in the frequency response pictured above). Unfortunately, the
filter was less successful as an anti-aliasing filter, as only 8dB had been
removed by 25Hz. This is certainly an area that would need further looking into
were the design to be taken any further.

Another issue that I identified later in the project was that the output of the
circuit was biased at 4.5V. As the range of the ADC of the nRF51822 is 0 - 5V,
this meant that we were not taking full advantage of the available resolution of
the ADC, as we could have a maximum output swing of 1V.

While this turned out to not normally be an issue, we did occasionally find that
the ADC was saturated at 5V, so a future revision of the circuit should include
re-biasing the output to 2.5V.

It would also have been worth spending more time investigating "off the shelf"
alternatives - while the circuit performance was acceptable, better results may
have been obtained by using an IC such as the Analog Devices AD8232 [^L7].

### Vest Electrodes

Up to this point, Roy and I had been testing using "Skintact" electrodes - an "off the
shelf" product that is designed to achieve good electrical contact between the
electrode and the skin. Unfortunately, the electrodes are single use and are
also uncomfortable (particularly when removing them!).

As part of the project we wanted to integrate the ECG electrodes into the vest,
removing the need for single-use electrodes and providing more comfort to the
wearer. We also spent time investigating different placements of the electrodes,
with the aim of reducing movement artifacts (caused by electrical activity in
other muscles) and obtaining an acceptable input signal.

#### Electrode Placement

The generally accepted electrode placement for a 3 lead ECG has the -ve
electrode on the right side of the chest, just below the shoulder bone, the
ground electrode is placed on the left side of the chest, opposite the -ve
electrode and the +ve electrode is placed in the 5th or 6th intercostal space
on the left side of the chest. Unfortunately, very large movement artifacts are
easily introduced, causing a complete loss of our desired signal.

<table>
  <tr>
    <td>
      <img src="electrode_placement_trials/placement6.jpg">
    </td>
    <td>
      <img src="electrode_placement_trials/placement6_waveform_normal.png">
    </td>
    <td>
      <img src="electrode_placement_trials/placement6_waveform_movement.png">
    </td>
  </tr>
  <tr class="img-caption">
    <td></td>

    <td>
      With little movement, a very clear trace is obtained (although in the
      image the +ve and -ve electrodes have been incorrectly connected,
      resulting in an inverted trace).
    </td>

    <td>
      However, with movement, the trace becomes unintelligible.
    </td>
  </tr>
</table>

Roy and I investigated a number of different electrode placements, but after
a little research, I came across an alternative electrode configuration
which is recommended for use in exercise physiology (which involves large
amounts of movement during tests). The configuration, introduced in "Exercise
Physiology: Nutrition, Energy, and Human Performance" [^2], has the ground
electrode on the sternum, with the -ve and +ve electrodes in the 5th intercostal
space on each side of the chest.

<table>
  <tr>
    <td>
      <img alt="Alternative electrode placement" src="pictures/bipolar configuration.png">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      From "Exercise Physiology: Nutrition, Energy, and Human Performance" [^2]
    </td>
  </tr>
</table>

This placement produces a satisfactory trace, pictured below, which is less
susceptible to movement artifacts.

<table>
  <tr>
    <td>
      <img src="electrode_placement_trials/placement1.jpg">
    </td>
    <td>
      <img src="electrode_placement_trials/placement1_waveform.png">
    </td>
  </tr>
</table>

This positioning is also suggested by Hakyung Cho and Joo Hyeon Lee in their
paper "A Study on the Optimal Positions of ECG Electrodes in a Garment for the
Design of ECG-Monitoring Clothing for Male" (sic) [^3].

When integrating the electrodes into the shirt (discussed in more detail below),
we found that moving the ground electrode to the right shoulder produced a very
similar trace but provided better contact with the skin.

#### Electrode design

Having decided on a suitable placement for the electrodes, I then spent a small
amount of time investigating different materials that could be used for the
electrodes. A number of papers ([^4][^5] to list two) have been published on
this subject in recent years, and provide interesting reading.

Unfortunately, the lead time and expense of such materials meant that it was not
practical to use such materials in the project. Instead, Roy and I attempted a
few different solutions.

One option that we considered was using parts of the Skintact electrodes, as
pictured below:

![Fixing Skintact electrodes into the vest](pictures/cut up skintact positions.jpg)

Unfortunately, we found that the sponge material used in the electrodes became
very fragile when it dried out making it unsuitable for longer term use.

I decided to investigate using conductive copper tape. This was cut into small
sections of approximately 15mm, and stuck to the inside of the vest. While this
was somewhat successful, I found that performance was improved by adding a
slight bulge to the electrode. By wrapping the tape round a metal stud, the
contact area is pushed into the skin a little more, improving the contact surface.

<table>
  <tr>
    <td>
      <img alt="Copper tape electrodes" src="pictures/conductive tape.jpg">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      An example of a copper tape electrode
    </td>
  </tr>
</table>

While the copper tape electrodes performed reasonably well while the wearer was
stationary, we once again found that movement caused the signal to be lost.
Given the limited time available I suggested sewing small patches of cloth over
the electrodes, then using an "off the shelf" electrode gel to try and improve
the contact between the skin and the electrode - even during movement. The cloth
helped to keep the gel in place, and the gel did indeed reduce movement artifacts
seen with the dry electrodes.

#### Evaluation

The vest is relatively comfortable to wear, with the main discomfort being
caused by the poor integration of the signal wires into the vest.

The requirement to use a conductive gel is disappointing, and makes putting on
the vest difficult. While not particularly uncomfortable, the design would be
significantly improved if this requirement could be removed. Given the amount
of research into conductive materials and wearable technology, it is likely that
this could be overcome with a little more time and research.

The output obtained from the vest leaves much to be desired.

The R and S sections of the trace are quite clearly visible (although small),
with the Q section of the trace occasionally obtained. However, the T section of
the trace is significantly distorted, and the P section is rarely seen.

<table>
  <tr>
    <td>
      <img src="waveforms/ECG output waveform.png">
    </td>
    <td>
      <img src="waveforms/vest final.png">
    </td>
    <td>
      <img src="waveforms/vest final movement.png">
    </td>
  </tr>

  <tr class="img-caption">
    <td>
      The trace obtained using Skintact electrodes
    </td>
    <td>
      The final output from the vest and ECG circuit
    </td>
    <td>
      Movement artifacts seen in the final output
    </td>
  </tr>
</table>

As seen above, movement is still an issue. However, even during movement R and S
sections of the ECG trace can be identified. While it has not been possible as
part of the project, I would like to investigate in the future whether
digital signal processing (particularly in combination with other sensors, such
as accelerometers) could be used to recover a reasonable ECG trace.

### Thermometer Circuit

A reasonably late addition to the vest was adding a thermistor and incorporating
a potential divider circuit in the belt pack so that the vest could measure the body
temperature of the wearer.

I designed the (very simple) circuit for the sensor, which consisted of a
potential divider fed into an op-amp. The op-amp provided a suitably low output
impedance, ensuring that the measurement wasn't affected by current flowing into
the ADC of the nRF51822.

The thermistor was sewn into the vest under the right armpit. This is one of the
few locations on the body where skin temperature gives a good indication of core
body temperature.

The voltage produced by the potential divider was then converted into a
temperature by software running on the nRF51822, as discussed in the following
section.

#### Evaluation

The thermometer circuit was very simple and provided reasonable performance.
Further testing and validation of the performance of the sensor would be required
to give a more thorough evaluation of the sensor, as the sensor was only tested
at room temperature and body temperature due to time constraints.

### mbed Programming

I was solely responsible for writing the software that ran on the nRF51822.

For the most part, the software is very simple. As the mbed libraries contain
all the code required for the setup and use of the ADC and Bluetooth chip, all
that was required was to link the two together and perform simple arithmetic on
the temperature sensor readings to convert the obtained voltage to degrees
celsius.

#### ECG Sampling

In order to show high-frequency components of the ECG trace, one must sample the
ECG output as frequently as possible. Sampling was achieved by setting up a
`Ticker`, which interrupts the CPU at a defined interval and causes a reading
from the ADC to be taken. The value is then transmitted using Bluetooth Low
Energy.

Due to the overhead of sampling the analogue signal and transmitting the new
value, I found that the minimum practical interval for sampling was 20ms. This
gives a sampling frequency of 50Hz, which is sufficient for sampling signals of
up to 25Hz.

#### Temperature Sampling and Calculation

For the temperature measurement obtained to be useful, I needed to convert the
voltage obtained from the thermistor into degrees celsius. The temperature (in
degrees Kelvin) of a thermistor can be approximated using the extended
"Steinhart and Hart" formula:

$$
  T^{-1} = A_1 + B_1 \times ln(R / R_{ref}) + C_1 \times ln^2(R / R_{ref}) + D_1 \times ln^3(R/R_{ref})
$$

where $$A_1$$, $$B_1$$, $$C_1$$ and $$D_1$$ are constants specific to the
thermistor. These values were obtained from the thermistor's datasheet [^6].

Having calculated $$T$$, it was then simply a case of subtracting 273 to convert
to degrees celsius.

As body temperature changes relatively infrequently, the temperature was only
sampled once every second. While a smaller interval could have been used, this
would have increased the minimum sampling interval for the ECG sensor with
little gain.

#### Evaluation

The software was functional, ensuring that values obtained from the two sensors
were correctly sampled and transmitted. However, better sampling rates may have
been achieved by storing a number of samples and transmitting them in chunks
(reducing the amount of time spent transmitting).

If more time were available, it would be worth spending a significant amount of
time investigating more efficient ways of transmitting the data obtained, as
this would appear to be the major bottleneck in the system.

### Packaging

I was responsible for integrating the electrodes and thermistor into the
compression shirt, and building a belt pack for the electronics.

I sew the ECG electrodes, thermistor and stranded cable into the inside of a
compression shirt. This ensured that the sensors remained in the same place, and
the cabling was kept tidy.

<table>
  <tr>
    <td>
      <img alt="Inside of the compression shirt" src="pictures/shirt inside.png">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      The inside of the compression shirt
    </td>
  </tr>
</table>

The 5 cables coming out of the shirt were then loomed together using AT7 PVC
tape, and connected to a male 9 pin D-Type connector. Using a D-type connector
allows easy disconnection of the shirt from the belt pack, which allows the
shirt to be washed.

<table>
  <tr>
    <td>
      <img alt="The belt pack, opened to show components" src="pictures/case.jpg">
    </td>
  </tr>
  <tr class="img-caption">
    <td>
      The belt pack, opened to show components
    </td>
  </tr>
</table>

The ECG and thermometer circuits, together with 3 x 9V batteries and the nRF51-DK
were placed into a black plastic case. On the front of the case, I added a power
switch, indicator LED, and a female 9 pin D-Type connector. I also added 2 female
headers which were connected to the output of the ECG circuit to allow the
output to be recorded easily once the case has been closed for the purposes of
evaluation and composing the group's reports.

#### Evaluation

Unfortunately, the belt pack was very large. This is largely due to the size of
the nRF51-DK, and the ECG circuit PCB. This made it cumbersome to carry around,
and would need to be improved if more time were available. The compression shirt
worked reasonably well, although use of thinner stranded cable would have
reduced the small amount of discomfort caused by the routing of sensor cables.

Website
-------

I was also responsible for the design and implementation of the group website.

The website has two primary functions - as well as hosting the group's reports,
the website also displays the data obtained from the health monitoring vest.

The website has been built as a "mock-up" of what a production site may look
like, with the homepage advertising the product and a dashboard for users to view
data obtained from the vest.

Users would use the "Login" button in the top left to access their own data.
Since the API does not yet handle authentication, any email address and password
may be used to login at this time. Unfortunately, the "historic" BPM graph is
also only a proof of concept, as the data has not been presented by the API.

Taking into account the web hosting facilities that were made available, I
decided it would be best to create a "static" website (that is, one where pages
are not generated by the server when they are requested) and make use of
javascript to pull data from the API server and Firebase.

### Backbone

In order to increase the maintainability of the site, I decided to use the
Backbone.JS [^L1] library which provides base classes for models, collections,
and views. This allows a developer to easily split a potentially fairly large
amount of javascript into discrete components.

On top of Backbone.JS, I also used the Marionette library [^L2] which removes a
large amount of "boilerplate" code that is often associated with Backbone
applications.

### Gulp

A number of different tools have been used to make developing the
website easier. JavaScript code has been written in CoffeeScript [^L3], as this makes
files easier to read and provides a number of useful features such as classes
(which aren't otherwise available in JavaScript). Stylesheets have been written
using SCSS [^L4], which allows classes to be nested and also provides a number of
useful helper functions.

Both of these tools require that code is compiled before it can be served to the
user. Add to this a number of libraries that have made front-end development
easier (such as the Bootstrap CSS library [^L5]), and it is clear that the build
process is non-trivial.

Thankfully, a number of tools exist to automate the build process. I decided to
use Gulp [^L6] - a relatively new tool designed for automating build processes
that I hadn't used before - as this provided a good opportunity to learn how to
use it.

Gulp is configured using a `gulpfile`, which defines a number of task "streams".
A stream is created by selecting source files (such as CoffeeScript files), then
run through a plugin that performs some manipulation on the stream (such as
a CoffeeScript compiler), and output to target - either a single file or a
directory.

The final `gulpfile` is available in the `website` section of the source code,
and defines tasks for compiling CoffeeScript, SCSS, handlebars templates, and
markdown, as well as tasks for moving dependencies into accessible locations.

### Evaluation

The website is currently fairly simple, but successfully shows the data obtained
from the vest. It has been written in such a way that adding additional sensors
and features would be relatively simple.

References
----------

[^1]:
  Obstructive Pulmonary Disease: Definition and Epidemiology
  David M Mannino MD
  Accessed 2016-01-07

Links
-----

[^L1]:
   http://www.bloomberg.com/news/articles/2015-07-21/google-s-calico-to-scour-ancestry-com-data-for-longevity-genes
[^L2]:
   http://www.calicolabs.com/
[^L3]:
   http://www.ecrc.ed.ac.uk/Researchers/item/Dr-Andy-Sims.html