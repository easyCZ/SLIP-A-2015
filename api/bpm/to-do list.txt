5) R - justify why it's ok for this method to have troubles with high heart rates
	a) wouldn't detect peaks anyways because data is not dense enough. Give bound for BPM with current data density.
6) Clean-up
	a) local.py
	b) services.py

7) graph how window length affects results
8) crop computational effort.
	a) might not be necessary if we are only using small windows
9) Test emulator start and finish times
10) justify not doing regression
11) why does it take warm-up time
12) compare fluctuations in bpm to fluctuations in actual heart_beat
13) need to check previous points part. 
14) improve text_back system
	a) objectify output from get_beats()
15) change setting to be more user friendly and easy to follow
16) be more consistent with use of lists or dictionaries. would allow me to cut down on number of functions( and lines). Probably use dictionaries only.
17) get rid of dummies
18) more flexibility with step1 function settings
19) confirm dictionary minimums
20) remove repitition in step15 and step2 functions
21) google code formatting
22) add step 15 methods
23) rename step methods to be more intuitive

1) fix benchmarks - CHECK
2) create bullshit detection - grrrrr
3) change to growing window - create window size indicator - CHECK
3.5) clean-up
3.6) ripple through BS
4) begin testing
5) improve step 1 method to contain beat shape or something


text_back
'empty' = power set empty
number = percentage BS

which methods 0,1,2
what were the benchmarks?
I want to iterate over methods

object CHOSEN
object of all methods or object per method?

window_length

1) what do I want in test feedback?
	a) bpm vs actual
	b) bad_data_factor 
	c) at_risk
2) figure out a way to loop through settings
